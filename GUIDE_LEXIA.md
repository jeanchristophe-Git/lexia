# ğŸ‡¨ğŸ‡® LexIA - Guide Complet du Projet

> Guide pour comprendre LexIA si tu connais seulement Next.js, Prisma et les bases

---

## ğŸ“– Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Comment Ã§a marche ?](#comment-Ã§a-marche)
3. [C'est quoi ChromaDB ?](#cest-quoi-chromadb)
4. [Architecture du projet](#architecture-du-projet)
5. [Installation et setup](#installation-et-setup)
6. [Lancer le scraping](#lancer-le-scraping)
7. [Comment Next.js utilise les donnÃ©es](#comment-nextjs-utilise-les-donnÃ©es)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Vue d'ensemble

**LexIA** est un assistant juridique IA pour la CÃ´te d'Ivoire qui :
1. **Scrape** les sites officiels ivoiriens (lois, codes, etc.)
2. **Stocke** les donnÃ©es dans PostgreSQL (Prisma) + ChromaDB
3. **RÃ©pond** aux questions avec Groq en utilisant ces donnÃ©es

### Le flow simple

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Utilisateurâ”‚
â”‚   pose une  â”‚
â”‚   question  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Next.js API (/api/chat) â”‚
â”‚  1. Cherche docs pertinents â”‚
â”‚  2. Envoie Ã  Groq + contexteâ”‚
â”‚  3. Retourne rÃ©ponse+sourcesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼              â–¼              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚PostgreSQLâ”‚   â”‚ChromaDB  â”‚   â”‚  Groq    â”‚
      â”‚ (Prisma) â”‚   â”‚(Vecteurs)â”‚   â”‚  (IA)    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–²              â–²
            â”‚              â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Python Scraper     â”‚
         â”‚  (Lance 1x/jour)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤” Comment Ã§a marche ?

### Partie 1 : Le scraping (Python)

Le script Python `scraper_simple.py` fait Ã§a :

```python
# 1. Va sur les sites officiels
sites = ["jo.gouv.ci", "cepici.ci", "dgi.gouv.ci"]

# 2. Extrait les articles de loi
articles = extraire_articles(sites)

# 3. Sauvegarde dans 2 endroits
PostgreSQL.save(articles)   # â†’ Pour historique/metadata
ChromaDB.save(articles)     # â†’ Pour recherche intelligente
```

**Pourquoi 2 endroits ?**
- **PostgreSQL** (Prisma) : Stockage classique, historique
- **ChromaDB** : Moteur de recherche intelligent (expliquÃ© plus bas)

### Partie 2 : L'API Next.js

Quand un user pose une question :

```typescript
// app/api/chat/route.ts

export async function POST(request) {
  const { question } = await request.json();

  // 1ï¸âƒ£ CHERCHE les docs pertinents dans ChromaDB
  const docs = await chromaDB.search(question); // Top 5 articles

  // 2ï¸âƒ£ CONSTRUIT le contexte pour l'IA
  const context = docs.map(d => d.content).join('\n');

  // 3ï¸âƒ£ ENVOIE Ã  Groq
  const response = await groq.chat({
    messages: [
      { role: 'system', content: 'Tu es LexIA...' },
      { role: 'system', content: `Documents: ${context}` },
      { role: 'user', content: question }
    ]
  });

  // 4ï¸âƒ£ RETOURNE la rÃ©ponse + sources
  return { answer: response, sources: docs };
}
```

---

## ğŸ” C'est quoi ChromaDB ?

**ChromaDB = Google mais pour tes documents juridiques**

### Le problÃ¨me sans ChromaDB

```
User: "Quel est le rÃ©gime fiscal des startups ?"

âŒ Recherche SQL classique:
SELECT * FROM documents
WHERE content LIKE '%rÃ©gime%'
   OR content LIKE '%fiscal%'
   OR content LIKE '%startup%'

â†’ Trouve 1000 rÃ©sultats non pertinents
â†’ L'IA est perdue avec trop d'infos
â†’ RÃ©pond n'importe quoi
```

### La solution avec ChromaDB

```
User: "Quel est le rÃ©gime fiscal des startups ?"

âœ… ChromaDB comprend le SENS:
â†’ Trouve les 5 articles LES PLUS pertinents:
  1. Code Investissement Art.25 (exonÃ©rations)
  2. Loi fiscale startups 2023
  3. DÃ©cret avantages jeunes entreprises

â†’ L'IA lit SEULEMENT ces 5 articles
â†’ RÃ©pond avec prÃ©cision et sources
```

### Comment ChromaDB fait Ã§a ?

ChromaDB transforme le texte en **vecteurs** (nombres) :

```
"CrÃ©er une SARL" â†’ [0.2, 0.8, 0.1, 0.5, ...]
"Fonder une sociÃ©tÃ©" â†’ [0.21, 0.79, 0.12, 0.48, ...]
                        â†‘ TrÃ¨s similaire !

"RÃ©gime fiscal" â†’ [0.9, 0.1, 0.7, 0.2, ...]
                   â†‘ ComplÃ¨tement diffÃ©rent
```

Il trouve les textes avec des vecteurs **proches** = sens similaire.

**En gros : ChromaDB comprend que "SARL" et "sociÃ©tÃ©" parlent de la mÃªme chose, mÃªme sans mot-clÃ© exact.**

---

## ğŸ—ï¸ Architecture du projet

### Next.js (Frontend + API) - Ce que tu connais dÃ©jÃ 

```
app/
â”œâ”€â”€ page.tsx              â†’ Dashboard React
â”œâ”€â”€ api/
â”‚   â””â”€â”€ chat/
â”‚       â””â”€â”€ route.ts      â†’ API qui rÃ©pond aux questions
â””â”€â”€ historique/
    â””â”€â”€ page.tsx          â†’ Page historique (Ã  crÃ©er)

prisma/
â””â”€â”€ schema.prisma         â†’ Models : User, Conversation, LegalDocument
```

### Python (Scraping) - Nouveau pour toi

```
scraper/
â”œâ”€â”€ scraper_simple.py     â†’ Script principal
â”‚   â”œâ”€ scrape_sites()     â†’ Va chercher les lois
â”‚   â”œâ”€ save_to_prisma()   â†’ Sauvegarde PostgreSQL
â”‚   â””â”€ save_to_chroma()   â†’ Sauvegarde ChromaDB
â”‚
â”œâ”€â”€ chromadb_setup.py     â†’ Initialise ChromaDB
â”œâ”€â”€ requirements.txt      â†’ Comme package.json mais Python
â””â”€â”€ .env.example          â†’ Variables d'environnement
```

### ChromaDB (Base vectorielle) - Nouvelle tech

```
data/
â””â”€â”€ chroma_db/            â†’ Fichiers gÃ©nÃ©rÃ©s automatiquement
    â”œâ”€â”€ index/            â†’ Index des vecteurs
    â””â”€â”€ data/             â†’ DonnÃ©es
```

**Tu n'as JAMAIS Ã  toucher ces fichiers** - ChromaDB gÃ¨re tout.

---

## ğŸš€ Installation et setup

### 1. VÃ©rifier que Python est installÃ©

```bash
python --version
# Doit afficher : Python 3.10 ou plus
```

Si pas installÃ© :
- **macOS** : `brew install python`
- **Windows** : TÃ©lÃ©charge sur python.org
- **Linux** : `sudo apt install python3`

### 2. Installer les dÃ©pendances Python

```bash
cd scraper
pip install -r requirements.txt
```

**C'est comme `npm install` mais pour Python.**

### 3. Configurer le `.env`

Tu as dÃ©jÃ  `DATABASE_URL` dans ton `.env` Next.js ? Parfait !

VÃ©rifie juste que c'est bien lÃ  :

```env
DATABASE_URL="postgresql://user:pass@localhost:5432/lexia"
GROQ_API_KEY="gsk_..."
```

Le script Python va utiliser les **mÃªmes** variables.

### 4. CrÃ©er les tables Prisma (si pas dÃ©jÃ  fait)

```bash
npx prisma db push
```

---

## ğŸ•·ï¸ Lancer le scraping

### PremiÃ¨re fois

```bash
cd scraper
python scraper_simple.py
```

**Tu vas voir :**

```
âœ… ConnectÃ© Ã  PostgreSQL (Prisma)
âœ… ChromaDB initialisÃ©

ğŸ“¥ Scraping journal_officiel...
  âœ“ Loi nÂ°2024-123 relative aux sociÃ©tÃ©s
  âœ“ DÃ©cret nÂ°2024-456 portant crÃ©ation

ğŸ“¥ Scraping cepici...
  âœ“ Guide crÃ©ation entreprise
  âœ“ ProcÃ©dures investissement

ğŸ’¾ Sauvegarde PostgreSQL...
  âœ“ 25 documents sauvegardÃ©s

ğŸ”¢ Sauvegarde ChromaDB...
  âœ“ 25 vecteurs gÃ©nÃ©rÃ©s et indexÃ©s

ğŸ‰ TERMINÃ‰ - 25 documents scrapÃ©s
```

### VÃ©rifier dans Prisma

```bash
npx prisma studio
```

Va sur la table `LegalDocument` â†’ Tu dois voir tes 25 documents !

### Scraping automatique (optionnel)

Pour scraper tous les jours automatiquement :

**macOS/Linux** :
```bash
# Ouvrir crontab
crontab -e

# Ajouter cette ligne (scrape tous les jours Ã  2h du matin)
0 2 * * * cd /chemin/vers/ton/projet/scraper && python scraper_simple.py
```

**Windows** : Utilise le Planificateur de tÃ¢ches

---

## ğŸ”— Comment Next.js utilise les donnÃ©es

### Dans ton API route : `app/api/chat/route.ts`

```typescript
import { ChromaClient } from 'chromadb';

// ğŸ”— Connexion Ã  ChromaDB (donnÃ©es scrapÃ©es)
const client = new ChromaClient({
  path: './data/chroma_db'
});

export async function POST(request: NextRequest) {
  const { question } = await request.json();

  // 1ï¸âƒ£ RECHERCHE dans ChromaDB
  const collection = await client.getCollection({
    name: 'lexia_legal_docs'
  });

  const results = await collection.query({
    queryTexts: [question],
    nResults: 5  // Top 5 docs pertinents
  });

  // 2ï¸âƒ£ CONTEXTE pour Groq
  const context = results.documents[0]
    .map((doc, i) => {
      const meta = results.metadatas[0][i];
      return `SOURCE: ${meta.title}\n${doc}`;
    })
    .join('\n\n---\n\n');

  // 3ï¸âƒ£ GROQ gÃ©nÃ¨re la rÃ©ponse
  const messages = [
    { role: 'system', content: LEXIA_SYSTEM_PROMPT },
    { role: 'system', content: `Documents:\n${context}` },
    { role: 'user', content: question }
  ];

  const response = await groq.chat.completions.create({
    messages,
    model: 'llama-3.3-70b-versatile'
  });

  // 4ï¸âƒ£ RETOURNE avec sources
  return NextResponse.json({
    answer: response.choices[0].message.content,
    sources: results.metadatas[0].map(m => ({
      title: m.title,
      url: m.url
    }))
  });
}
```

### Installer ChromaDB pour Next.js

```bash
npm install chromadb
```

---

## ğŸ§ª Tester le systÃ¨me complet

### Test 1 : VÃ©rifier ChromaDB

```bash
cd scraper
python chromadb_setup.py
```

Doit afficher :
```
âœ… ChromaDB opÃ©rationnel
ğŸ“Š Documents indexÃ©s : 25
```

### Test 2 : Tester l'API Next.js

Lance ton serveur :
```bash
npm run dev
```

Test avec curl :
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d "{\"question\": \"Comment crÃ©er une SARL en CÃ´te d'Ivoire ?\"}"
```

Tu devrais recevoir une rÃ©ponse avec sources !

### Test 3 : Tester le Dashboard

Va sur `http://localhost:3000`

Pose une question dans l'interface â†’ Tu dois voir :
- La question s'affiche
- Loading avec les 3 points
- RÃ©ponse de LexIA avec sources

---

## ğŸ”§ Troubleshooting

### Erreur : "No module named 'chromadb'"

**Solution :**
```bash
cd scraper
pip install chromadb
```

### Erreur : "Could not connect to database"

**Solution :**
VÃ©rifie que PostgreSQL tourne :
```bash
# macOS
brew services start postgresql

# Linux
sudo service postgresql start

# Windows
# DÃ©marre PostgreSQL via Services ou pgAdmin
```

### ChromaDB : "Collection not found"

**Solution :**
Relance le scraper pour crÃ©er la collection :
```bash
python scraper_simple.py
```

### API Next.js : "chromadb is not defined"

**Solution :**
Installe chromadb pour Node.js :
```bash
npm install chromadb
```

### Le scraper trouve 0 documents

**Raison :** Les sÃ©lecteurs CSS ne matchent pas la structure du site.

**Solution :**
1. Ouvre le site dans le navigateur
2. Inspecte l'Ã©lÃ©ment (F12)
3. Trouve les vrais sÃ©lecteurs CSS
4. Modifie `scraper_simple.py` ligne 45

Exemple :
```python
# Au lieu de
articles = soup.find_all('article')

# Utilise ce que tu trouves dans l'inspecteur
articles = soup.select('div.legal-document')
```

---

## ğŸ“š Ressources pour apprendre

### Si tu veux comprendre Python

- [Python en 10 min](https://learnxinyminutes.com/docs/python/)
- C'est comme JavaScript mais avec des `:` au lieu de `{}`

### Si tu veux comprendre ChromaDB

- [ChromaDB Docs](https://docs.trychroma.com/)
- Pense Ã  Ã§a comme Algolia mais pour la recherche sÃ©mantique

### Si tu veux amÃ©liorer le scraping

- [BeautifulSoup Docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- C'est comme `document.querySelector()` en Python

---

## ğŸ¯ Prochaines Ã©tapes

### V1 (Actuel)
âœ… Scraping de base
âœ… Stockage PostgreSQL
âœ… ChromaDB pour recherche
âœ… API Next.js fonctionnelle

### V2 (Ã€ venir)
- [ ] Scraper plus de sources officielles
- [ ] Page historique des conversations
- [ ] Export des rÃ©ponses en PDF
- [ ] Authentification utilisateurs

### V3 (Futur)
- [ ] Scraping automatique quotidien
- [ ] Notifications nouvelles lois
- [ ] Abonnement premium
- [ ] App mobile

---

## ğŸ’¡ Points clÃ©s Ã  retenir

1. **Python scrape** â†’ **Sauvegarde dans Prisma + ChromaDB**
2. **Next.js lit** â†’ **ChromaDB trouve docs pertinents**
3. **Groq rÃ©pond** â†’ **Avec contexte des docs**
4. **Tu n'as pas besoin de tout comprendre** â†’ Lance les scripts, Ã§a marche !

---

## ğŸ†˜ Besoin d'aide ?

Si quelque chose ne marche pas :
1. Lis la section Troubleshooting ci-dessus
2. Check les logs Python : `python scraper_simple.py 2>&1 | tee scraper.log`
3. Check les logs Next.js dans la console

---

**Fait avec â¤ï¸ pour la CÃ´te d'Ivoire** ğŸ‡¨ğŸ‡®
